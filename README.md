# ğŸ”® Glyph

Glyph is a local-first AI-powered Go code generation tool that transforms natural language instructions into working implementations.

## Features

- **Natural Language Programming**: Describe what you want in plain language
- **In-Place Generation**: Replaces `panic("not implemented")` with actual code
- **Context-Aware**: Understands your function signatures and surrounding code
- **Local-First**: Everything runs on your machine with Ollama
- **Real-time Streaming**: See generation progress as it happens
- **Multiple Modes**: Specialized modes for different use cases (Spanner, generic Go)

## Installation

```bash
go install github.com/rail44/glyph@latest
```

Or build from source:

```bash
git clone https://github.com/rail44/glyph.git
cd glyph
go build -o glyph .
```

## Prerequisites

- Go 1.21 or later
- [Ollama](https://ollama.ai/) installed and running
- A compatible AI model (e.g., `devstral`)

## Quick Start

1. Write your Go code with `// glyph:` comments:

```go
package main

import "context"

// glyph: emailã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æ¤œç´¢
func GetUserByEmail(ctx context.Context, email string) (*User, error) {
    panic("not implemented")
}

// glyph: å‰²å¼•ç‡ã‚’è¨ˆç®—ã™ã‚‹
// è³¼å…¥é‡‘é¡ãŒ10000å††ä»¥ä¸Šã§10%å‰²å¼•
// ä¼šå“¡ãƒ©ãƒ³ã‚¯ãŒGoldãªã‚‰è¿½åŠ 5%å‰²å¼•
func CalculateDiscount(amount float64, memberRank string) float64 {
    panic("not implemented")
}
```

2. Generate implementations:

```bash
glyph generate main.go
```

3. Watch the streaming progress as code is generated in real-time!

## How It Works

1. **Comment Detection**: Glyph finds functions marked with `// glyph:` comments
2. **Context Analysis**: Analyzes function signatures and surrounding code
3. **AI Generation**: Sends context and instructions to your local AI model
4. **Real-time Streaming**: Shows generation progress with live feedback
5. **Code Replacement**: Replaces panic statements with generated implementations
6. **Format & Save**: Formats the code and saves it back to the file

## Configuration

Configuration is handled via command-line flags:

```bash
# Use different model
glyph generate --model qwen2.5-coder main.go

# Use different Ollama host
glyph generate --host http://192.168.1.100:11434 main.go
```

Defaults:
- Model: `devstral`
- Host: `http://localhost:11434`

## Commands

### Generate
```bash
glyph generate <file> [flags]
```

Generates implementations for all functions with `// glyph:` comments.

**Flags:**
- `--mode string`: Generation mode (`spanner` or `generic`, default: `generic`)
- `--model string`: AI model to use (default: `devstral`)
- `--host string`: Ollama host URL (default: `http://localhost:11434`)
- `--no-stream`: Disable streaming output (faster for scripting)
- `--debug-timing`: Show detailed timing information

### Performance Options

```bash
# Default: streaming with progress indication
glyph generate main.go

# Non-streaming for scripting/CI
glyph generate main.go --no-stream

# Debug performance issues
glyph generate main.go --debug-timing
```

## Writing Effective Instructions

### Basic Instructions
```go
// glyph: IDã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å–å¾—
func GetUser(id string) (*User, error) {
    panic("not implemented")
}
```

### Detailed Instructions
```go
// glyph: ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼ã‚’å®Ÿè¡Œ
// - ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’bcryptã§æ¤œè¨¼
// - æˆåŠŸæ™‚ã¯JWTãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆ
// - å¤±æ•—å›æ•°ã‚’Redisã§ã‚«ã‚¦ãƒ³ãƒˆ
func AuthenticateUser(email, password string) (*Token, error) {
    panic("not implemented")
}
```

### Method Generation
```go
type UserService struct {
    db *sql.DB
}

// glyph: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å–å¾—
func (s *UserService) GetAllUsers(ctx context.Context) ([]*User, error) {
    panic("not implemented")
}
```

## Modes

### Generic Mode (Default)
General-purpose Go code generation for any use case.

### Spanner Mode
Optimized for Google Cloud Spanner with:
- Parameterized queries
- Read-only transactions
- Proper error handling
- Index optimization

```bash
glyph generate --mode spanner user_service.go
```

## Performance Features

### Streaming Output
By default, Glyph shows real-time progress as AI generates your code:
- See dots appear as tokens are generated
- Get immediate feedback that generation is working
- Cancel if generation seems to be going wrong

### Optimized Prompts
Glyph automatically chooses the right prompt complexity:
- **Simple functions**: Minimal prompts for faster generation
- **Complex functions**: Detailed prompts with full context

### Timing Analysis
Use `--debug-timing` to identify performance bottlenecks:
```bash
glyph generate main.go --debug-timing
```

This shows:
- Time spent parsing
- AI model loading time
- First token latency
- Total generation time
- Tokens per second

## Best Practices

1. **Clear Instructions**: Be specific about what you want
2. **Context Matters**: Include relevant types and imports in your file
3. **One Thing at a Time**: Focus each function on a single responsibility
4. **Review Generated Code**: Always review and test generated implementations
5. **Use Streaming**: Watch progress to catch issues early

## Examples

See the `examples/` directory for more usage examples:
- `user_service.go`: Database operations with Spanner
- `calculator.go`: General computation functions

## Troubleshooting

### Slow Generation
- Use `--debug-timing` to identify bottlenecks
- Try simpler, more focused instructions
- Consider using a smaller/faster model

### Generation Stuck
- The streaming output shows if generation is progressing
- Cancel with Ctrl+C if needed
- Check that Ollama is running: `ollama list`

## License

MIT License - See LICENSE file for details