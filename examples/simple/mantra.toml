# mantra Configuration for Simple Examples with Ollama
# This example uses local Ollama with gpt-oss

# Model configuration
model = "gpt-oss:20b"

# Ollama API endpoint
url = "http://localhost:11434/v1"

# Output directory
dest = "../simple_mantra"

# API key (not needed for Ollama)
api_key = ""

# Debug logging to see generation details
log_level = "trace"
